{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7c500fa1-b6d2-4e15-a2cb-5a14c3614429",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "from tqdm import tqdm\n",
    "from options import TrainOptions\n",
    "from x_dataset import CGGANDataset\n",
    "from model import CHARACTERModel\n",
    "from utils import save_model\n",
    "\n",
    "from google.cloud import storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "04f2cdea-8f31-413a-86ae-d5c85237d890",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "opt = TrainOptions()   # get training options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d56feb46-f944-4b02-81e1-22fe312ccadb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "storage_client = storage.Client(opt.bucket_name)\n",
    "bucket = storage_client.bucket(opt.bucket_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a1e90de0-45c7-41ef-8c19-7fc44132b52c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = CGGANDataset(args=opt)\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    dataset, batch_size=opt.batch_size,\n",
    "    shuffle=True, sampler=None, drop_last=True, num_workers=int(opt.num_threads))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6bbda0d4-4508-4089-aca3-3e52431ad07a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Param count for Ds initialized parameters: 19541696\n",
      "Param count for Ds initialized parameters: 20591296\n",
      "Param count for Ds initialized parameters: 27289027\n"
     ]
    }
   ],
   "source": [
    "model = CHARACTERModel(opt=opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5b628cd3-23b5-42f8-8f04-cbf29e64f7bd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4ec80fd9-191f-4401-83a3-71af9729366f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.set_input(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5b674669-c494-48bb-bca5-854bd15e97bb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 3, 128, 128])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.img_write.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bcd9f8da-d05c-4344-92d1-ee7355a97b41",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 3, 128, 128])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.img_print.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "707180f8-4c21-405a-914f-a8f1898a3cbe",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Sizes of tensors must match except in dimension 1. Expected size 4 but got size 8 for tensor number 1 in the list.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m style_emd, style_fc, residual_features_style \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mnetStyleEncoder(model\u001b[38;5;241m.\u001b[39mimg_write)\n\u001b[1;32m      2\u001b[0m cont, residual_features \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mnetContentEncoder(model\u001b[38;5;241m.\u001b[39mimg_print) \n\u001b[0;32m----> 3\u001b[0m h \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnetdecoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcont\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresidual_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstyle_emd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstyle_fc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresidual_features_style\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/pytorch/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/ai_font/exp0604/cggan_multishot/unet.py:623\u001b[0m, in \u001b[0;36mdecoder_textedit_addskip.forward\u001b[0;34m(self, x, residual_features, style_emd, style_fc, residual_features_style)\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[38;5;66;03m# h = h.permute(0,2,3,1)\u001b[39;00m\n\u001b[1;32m    620\u001b[0m     \u001b[38;5;66;03m# h = self.linear_mix(h)\u001b[39;00m\n\u001b[1;32m    621\u001b[0m     \u001b[38;5;66;03m# h = h.permute(0,3,1,2)\u001b[39;00m\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m index \u001b[38;5;241m==\u001b[39m\u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 623\u001b[0m     h \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mh\u001b[49m\u001b[43m,\u001b[49m\u001b[43mresidual_features_style\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    624\u001b[0m     \u001b[38;5;66;03m#h = torch.cat((h,residual_features[4]),dim=1)\u001b[39;00m\n\u001b[1;32m    625\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m index \u001b[38;5;241m==\u001b[39m\u001b[38;5;241m2\u001b[39m:                   \n",
      "\u001b[0;31mRuntimeError\u001b[0m: Sizes of tensors must match except in dimension 1. Expected size 4 but got size 8 for tensor number 1 in the list."
     ]
    }
   ],
   "source": [
    "style_emd, style_fc, residual_features_style = model.netStyleEncoder(model.img_write)\n",
    "cont, residual_features = model.netContentEncoder(model.img_print) \n",
    "h = model.netdecoder(cont, residual_features, style_emd, style_fc, residual_features_style)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "515095b3-2da4-442f-962a-e1f4ee42539a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 512, 8, 8])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "residual_features[4].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7c384bc5-d378-49d9-a19b-712fce1a856a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 1024, 4, 4])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cont.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "08644697-79cd-48b5-83cd-8d4da79208c1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 1024, 4, 4])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "style_emd.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "014ec0a3-a582-43e2-aa8a-f270629e349c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GBlock(\n",
       "  (activation): ReLU()\n",
       "  (conv1): SNConv2d(2048, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv2): SNConv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv_sc): SNConv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (bn1): AdaIN2d(num_features=2048)\n",
       "  (bn2): AdaIN2d(num_features=512)\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.netdecoder.blocks[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "148f15b8-5746-4884-8124-6b4fd787a527",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1783/2200000 [38:06<817:59:41,  1.34s/it]"
     ]
    }
   ],
   "source": [
    "total_iters = 0                # the total number of training iterations\n",
    "total_steps = 440000*5\n",
    "pbar = tqdm(total=total_steps)\n",
    "while total_iters < total_steps:    # outer loop for different epochs; we save the model by <epoch_count>, <epoch_count>+<save_latest_freq>\n",
    "    model.train() \n",
    "\n",
    "    for i, data in enumerate(train_loader):  # inner loop within one epoch         \n",
    "        model.set_input(data)         # unpack data from dataset and apply preprocessing\n",
    "        model.optimize_parameters()   # calculate loss functions, get gradients, update network weights\n",
    "        \n",
    "        pbar.update(1)\n",
    "        total_iters += 1\n",
    "        \n",
    "        if total_iters % 10000 == 0:\n",
    "            state_dicts = model.get_state_dicts()\n",
    "            for k,v in state_dicts.items():\n",
    "                save_model(opt, bucket, v, f\"{k}__{total_iters}.pth\")\n",
    "            newlr = model.update_learning_rate()     \n",
    "            pbar.set_postfix(lr=f'{newlr:.{12}f}')# update learning rates at the end of every epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c7f552c-787d-4c9c-80fc-55180c1ae434",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-env-pytorch-pytorch",
   "name": "workbench-notebooks.m122",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m122"
  },
  "kernelspec": {
   "display_name": "PyTorch 1-13 (Local)",
   "language": "python",
   "name": "conda-env-pytorch-pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
