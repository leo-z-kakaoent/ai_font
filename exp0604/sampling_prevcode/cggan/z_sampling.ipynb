{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b292ae4-0d22-40fc-8756-bf6beba00e53",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import shutil\n",
    "\n",
    "from tqdm import tqdm\n",
    "from options import SamplingOptions\n",
    "from torch.utils.data import DataLoader\n",
    "from y_sample_dataset import SamplingDataset\n",
    "from model import CHARACTERModel\n",
    "from PIL import Image\n",
    "from google.cloud import storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a771b44-abad-4533-807f-67d95c93dde8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def tensor2im(input_image, imtype=np.uint8):\n",
    "    \"\"\"\"Converts a Tensor array into a numpy image array.\n",
    "\n",
    "    Parameters:\n",
    "        input_image (tensor) --  the input image tensor array\n",
    "        imtype (type)        --  the desired type of the converted numpy array\n",
    "    \"\"\"\n",
    "    if not isinstance(input_image, np.ndarray):\n",
    "        if isinstance(input_image, torch.Tensor):  # get the data from a variable\n",
    "            image_tensor = input_image.data\n",
    "        else:\n",
    "            return input_image\n",
    "        image_numpy = image_tensor[0].cpu().float().numpy()  # convert it into a numpy array\n",
    "        if image_numpy.shape[0] == 1:  # grayscale to RGB\n",
    "            image_numpy = np.tile(image_numpy, (3, 1, 1))\n",
    "        image_numpy = (np.transpose(image_numpy, (1, 2, 0)) + 1) / 2.0 * 255.0  # post-processing: tranpose and scaling\n",
    "    else:  # if it is a numpy array, do nothing\n",
    "        image_numpy = input_image\n",
    "    return Image.fromarray(image_numpy.astype(imtype))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ab7c1175-a341-4354-8b97-9bd612cfc4bd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "opt = SamplingOptions()\n",
    "os.makedirs(opt.savefd, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7bfc3b86-9749-4643-bf9a-40deeed08e58",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = SamplingDataset(opt)\n",
    "loader = DataLoader(dataset, batch_size=opt.batch_size, shuffle=False, drop_last=False, num_workers=int(opt.num_threads))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "014bc795-c58c-44f8-8fb9-1d16f1e67c95",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Param count for Ds initialized parameters: 19541696\n",
      "Param count for Ds initialized parameters: 20591296\n",
      "Param count for Ds initialized parameters: 27289027\n"
     ]
    }
   ],
   "source": [
    "model = CHARACTERModel(opt=opt)\n",
    "model.load_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "18ecb22f-1be8-4ed4-9e9d-a3ec36dcdee9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 350/350 [01:23<00:00,  4.19it/s, path=/home/jupyter/ai_font/data/reports/exp0604/cggan/cggan_full__카엔플린__힣.png]\n"
     ]
    }
   ],
   "source": [
    "# outer loop for different epochs; we save the model by <epoch_count>, <epoch_count>+<save_latest_freq>\n",
    "model.eval() \n",
    "pbar = tqdm(loader)\n",
    "for data in pbar:  # inner loop within one epoch         \n",
    "    model.set_input(data)         # unpack data from dataset and apply preprocessing\n",
    "    model.forward()\n",
    "    generated = model.img_print2write\n",
    "    for i in range(len(generated)):\n",
    "        img = tensor2im(generated[[i]])\n",
    "        font = model.writerID[i]\n",
    "        letter = model.image_paths[i]\n",
    "        path = f\"{opt.savefd}/{opt.tag}__{font}__{letter}.png\"\n",
    "        img.save(path)\n",
    "        pbar.set_postfix(path=path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22097694-fe56-4e66-b74c-0d3e821a221f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-env-pytorch-pytorch",
   "name": "workbench-notebooks.m121",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m121"
  },
  "kernelspec": {
   "display_name": "PyTorch 1-13 (Local)",
   "language": "python",
   "name": "conda-env-pytorch-pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
