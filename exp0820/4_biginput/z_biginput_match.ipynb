{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f44ceb8-ba09-4cf4-8f46-31627a9d4be3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.6.0 (SDL 2.28.4, Python 3.10.14)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from diffusers.optimization import get_scheduler\n",
    "from google.cloud import storage\n",
    "\n",
    "from dataset import FontDataset, CollateFN\n",
    "from model import FontDiffuserModel\n",
    "from criterion import ContentPerceptualLoss\n",
    "from build import build_unet, build_style_encoder, build_content_encoder, build_ddpm_scheduler\n",
    "from args import TrainPhase1Args\n",
    "from utils import x0_from_epsilon, reNormalize_img, normalize_mean_std, save_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e899401b-20d8-4576-988a-41c1eecd0bbf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TrainPhase1Args:\n",
    "    def __init__(self, r):\n",
    "        # My Configs\n",
    "        self.bucket_name = \"leo_font\"\n",
    "        self.savepath = \"exp0604/phase1\"\n",
    "        self.datapath = \"/home/jupyter/ai_font/data\"\n",
    "        self.scr = False\n",
    "        self.num_neg = None\n",
    "        self.experiment_name = \"phase1\"\n",
    "        self.resolution= r\n",
    "        self.content_font = '시스템굴림'\n",
    "        \n",
    "        # Given\n",
    "        self.unet_channels=(64, 128, 256, 512,)\n",
    "        self.beta_scheduler=\"scaled_linear\"\n",
    "        self.adam_beta1 = 0.9\n",
    "        self.adam_beta2 = 0.999\n",
    "        self.adam_weight_decay = 1e-2\n",
    "        self.adam_epsilon = 1e-08\n",
    "        self.max_grad_norm = 1.0\n",
    "        self.seed = 123\n",
    "        self.style_image_size=r\n",
    "        self.content_image_size=r \n",
    "        self.content_encoder_downsample_size=3\n",
    "        self.channel_attn=True \n",
    "        self.content_start_channel=64 \n",
    "        self.style_start_channel=64 \n",
    "        self.train_batch_size=8\n",
    "        self.perceptual_coefficient=0.01 \n",
    "        self.offset_coefficient=0.5 \n",
    "        self.max_train_steps=440000*5\n",
    "        self.ckpt_interval=40000 \n",
    "        self.gradient_accumulation_steps=1 \n",
    "        self.log_interval=50 \n",
    "        self.learning_rate=1e-4 \n",
    "        self.lr_scheduler=\"linear\" \n",
    "        self.lr_warmup_steps=10000 \n",
    "        self.drop_prob=0.1 \n",
    "        self.mixed_precision=\"no\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5479a49b-33f3-4cc6-a168-9e8eb83fd25c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load the down block  DownBlock2D\n",
      "Load the down block  MCADownBlock2D\n",
      "The style_attention cross attention dim in Down Block 1 layer is 1024\n",
      "The style_attention cross attention dim in Down Block 2 layer is 1024\n",
      "Load the down block  MCADownBlock2D\n",
      "The style_attention cross attention dim in Down Block 1 layer is 1024\n",
      "The style_attention cross attention dim in Down Block 2 layer is 1024\n",
      "Load the down block  DownBlock2D\n",
      "Load the up block  UpBlock2D\n",
      "Load the up block  StyleRSIUpBlock2D\n",
      "Load the up block  StyleRSIUpBlock2D\n",
      "Load the up block  UpBlock2D\n",
      "Param count for Ds initialized parameters: 20591296\n",
      "Get CG-GAN Style Encoder!\n",
      "Param count for Ds initialized parameters: 19541696\n",
      "Get CG-GAN Content Encoder!\n"
     ]
    }
   ],
   "source": [
    "r = 128\n",
    "args = TrainPhase1Args(r)\n",
    "unet = build_unet(args=args)\n",
    "style_encoder = build_style_encoder(args=args)\n",
    "content_encoder = build_content_encoder(args=args)\n",
    "noise_scheduler = build_ddpm_scheduler(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c4492241-a9ad-45d8-bfff-c8e46ac618fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = FontDiffuserModel(\n",
    "    unet=unet,\n",
    "    style_encoder=style_encoder,\n",
    "    content_encoder=content_encoder)\n",
    "model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ff3dfa3e-f846-49f6-a189-3c569dff6c76",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/pytorch/lib/python3.10/site-packages/diffusers/configuration_utils.py:140: FutureWarning: Accessing config attribute `num_train_timesteps` directly via 'DDPMScheduler' object attribute is deprecated. Please access 'num_train_timesteps' over 'DDPMScheduler's config object instead, e.g. 'scheduler.config.num_train_timesteps'.\n",
      "  deprecate(\"direct config name access\", \"1.0.0\", deprecation_message, standard_warn=False)\n",
      "/home/jupyter/ai_font/exp0820/4_biginput/model.py:34: FutureWarning: Accessing config attribute `style_encoder` directly via 'FontDiffuserModel' object attribute is deprecated. Please access 'style_encoder' over 'FontDiffuserModel's config object instead, e.g. 'unet.config.style_encoder'.\n",
      "  style_img_feature, _, _ = self.style_encoder(style_images)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[f.shape for f in style_structure_features] [torch.Size([2, 3, 128, 128]), torch.Size([2, 64, 64, 64]), torch.Size([2, 128, 32, 32]), torch.Size([2, 256, 16, 16]), torch.Size([2, 512, 8, 8]), torch.Size([2, 1024, 4, 4])]\n",
      "[f.shape for f in style_structure_features] [torch.Size([2, 3, 128, 128]), torch.Size([2, 64, 64, 64]), torch.Size([2, 128, 32, 32]), torch.Size([2, 256, 16, 16]), torch.Size([2, 512, 8, 8]), torch.Size([2, 1024, 4, 4])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter/ai_font/exp0820/4_biginput/model.py:40: FutureWarning: Accessing config attribute `content_encoder` directly via 'FontDiffuserModel' object attribute is deprecated. Please access 'content_encoder' over 'FontDiffuserModel's config object instead, e.g. 'unet.config.content_encoder'.\n",
      "  content_img_feature, content_residual_features = self.content_encoder(content_images)\n",
      "/home/jupyter/ai_font/exp0820/4_biginput/model.py:43: FutureWarning: Accessing config attribute `content_encoder` directly via 'FontDiffuserModel' object attribute is deprecated. Please access 'content_encoder' over 'FontDiffuserModel's config object instead, e.g. 'unet.config.content_encoder'.\n",
      "  style_content_feature, style_content_res_features = self.content_encoder(style_images)\n",
      "/home/jupyter/ai_font/exp0820/4_biginput/model.py:49: FutureWarning: Accessing config attribute `unet` directly via 'FontDiffuserModel' object attribute is deprecated. Please access 'unet' over 'FontDiffuserModel's config object instead, e.g. 'unet.config.unet'.\n",
      "  out = self.unet(\n"
     ]
    }
   ],
   "source": [
    "content_images = torch.ones([2,3,r,r]).cuda()\n",
    "style_images = torch.ones([2,3,r,r]).cuda()\n",
    "target_images = torch.ones([2,3,r,r]).cuda()\n",
    "\n",
    "noise = torch.randn_like(target_images)\n",
    "bsz = target_images.shape[0]\n",
    "timesteps = torch.randint(0, noise_scheduler.num_train_timesteps, (bsz,), device=target_images.device)\n",
    "timesteps = timesteps.long()\n",
    "\n",
    "noisy_target_images = noise_scheduler.add_noise(target_images, noise, timesteps)\n",
    "\n",
    "noise_pred, offset_out_sum = model(\n",
    "    x_t=noisy_target_images,\n",
    "    timesteps=timesteps,\n",
    "    style_images=style_images,\n",
    "    content_images=content_images,\n",
    "    content_encoder_downsample_size=args.content_encoder_downsample_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1df01262-6b69-4545-98ab-873bea3ad02f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unet.up_blocks[1].sc_interpreter_offsets[0].gnorm_s.weight.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4160491d-a427-49c6-851c-83a60f746759",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "a = torch.nn.MaxPool2d(kernel_size=2, stride=2, padding=0)(torch.ones([2,256,32,32]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "935d0118-527e-4043-bfa0-567f642fd7c2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 256, 16, 16])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3991c3ba-bbd8-49e0-bc8e-17938cf69509",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-env-pytorch-pytorch",
   "name": "workbench-notebooks.m123",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m123"
  },
  "kernelspec": {
   "display_name": "PyTorch 1-13 (Local)",
   "language": "python",
   "name": "conda-env-pytorch-pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
