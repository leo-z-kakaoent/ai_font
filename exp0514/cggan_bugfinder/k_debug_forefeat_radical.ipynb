{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "126350e7-e38a-4a49-afdb-684bf2337b2d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from networks import AttnDecoderRNN, CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6aa9582d-8cea-46b3-9c13-e7ac055cc0c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CAM_normD(nn.Module):\n",
    "    def __init__(self,nclass,channel_size,hidden_size,output_size,dropout_p=0.1,max_length = 64,D_ch =16, nWriter = 1300,iam = False):\n",
    "        super(CAM_normD,self).__init__()\n",
    "        self.encoder =CNN(channel_size)\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        self.decoder_forradical = AttnDecoderRNN(hidden_size, output_size, dropout_p,max_length)\n",
    "        # self.decoderfeat_forradical =nn.Sequential(\n",
    "        #     nn.Conv2d(256, 128, 3, 1, 1), nn.InstanceNorm2d(128), nn.PReLU(), nn.AvgPool2d(2, 2),\n",
    "        #     nn.Conv2d(128, 64, 3, 1, 1), nn.InstanceNorm2d(128), nn.PReLU(), nn.MaxPool2d(2, 2),\n",
    "        #     nn.Conv2d(64, 16, 3, 1, 1), nn.InstanceNorm2d(16), nn.PReLU(),\n",
    "        #     nn.Conv2d(16, 1, 3, 1, 1)\n",
    "        #     )        \n",
    "\n",
    "        self.decoderfeat_forradical0 =nn.Sequential(\n",
    "            nn.Conv2d(256, 128, 3, 1, 1), nn.InstanceNorm2d(128), nn.PReLU(), nn.AvgPool2d(2, 2),\n",
    "            nn.Conv2d(128, 64, 3, 1, 1)\n",
    "            )        \n",
    "\n",
    "        self.decoderfeat_forradical1 =nn.Sequential(\n",
    "            nn.InstanceNorm2d(128), nn.PReLU(), nn.MaxPool2d(2, 2),\n",
    "            nn.Conv2d(64, 16, 3, 1, 1), nn.InstanceNorm2d(16), nn.PReLU(),\n",
    "            nn.Conv2d(16, 1, 3, 1, 1)\n",
    "            )        \n",
    "\n",
    "        \n",
    "\n",
    "    def initHidden(batch_size,hidden_size):\n",
    "        result = torch.autograd.Variable(torch.zeros(1, batch_size, hidden_size))\n",
    "        return result\n",
    "\n",
    "    def forward(self, image, text_radical, length_radical):\n",
    "        \n",
    "        encode = self.encoder(image)\n",
    "        b, c, _, _ = encode.size() #batch,256\n",
    "        \n",
    "        # out, bottleneck_out = self.unetD(image)\n",
    "        out = self.D(image)\n",
    "        loss_forradical,new_encode= self.decoder_forradical(encode,image,text_radical,length_radical)\n",
    "        # pred_radical = self.decoderfeat_forradical(new_encode)\n",
    "        pred_radical0 = self.decoderfeat_forradical0(new_encode)\n",
    "        pred_radical1 = self.decoderfeat_forradical1(pred_radical0)\n",
    "        pred_radical = (pred_radical0, pred_radical1)\n",
    "        \n",
    "        return pred_radical, loss_forradical, out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0fd27d95-5f40-44d9-9f9d-b00ca583f406",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/jupyter/ai_font/data/pickle/letter2font.pickle'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m opt \u001b[38;5;241m=\u001b[39m TrainOptions()\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mx_dataset\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CGGANDataset\n\u001b[0;32m----> 5\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[43mCGGANDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mopt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m train_loader \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mDataLoader(\n\u001b[1;32m      7\u001b[0m     dataset, batch_size\u001b[38;5;241m=\u001b[39mopt\u001b[38;5;241m.\u001b[39mbatch_size,\n\u001b[1;32m      8\u001b[0m     shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, sampler\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, drop_last\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, num_workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mint\u001b[39m(opt\u001b[38;5;241m.\u001b[39mnum_threads))\n",
      "File \u001b[0;32m~/ai_font/exp0514/cggan_bugfinder/x_dataset.py:48\u001b[0m, in \u001b[0;36mCGGANDataset.__init__\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mletter_mapper_b \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_pickle(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/pickle/letter_mapper_b.pickle\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfont_mapper \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_pickle(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/pickle/font_mapper.pickle\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 48\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mletter2font \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_pickle\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/pickle/letter2font.pickle\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mletter_mapper_ab \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mletter_mapper_a\u001b[38;5;241m.\u001b[39msimilar \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mletter_mapper_b\u001b[38;5;241m.\u001b[39msimilar\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfonts \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfont_mapper\u001b[38;5;241m.\u001b[39mindex\n",
      "File \u001b[0;32m/opt/conda/envs/pytorch/lib/python3.10/site-packages/pandas/io/pickle.py:185\u001b[0m, in \u001b[0;36mread_pickle\u001b[0;34m(filepath_or_buffer, compression, storage_options)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;124;03mLoad pickled pandas object (or any object) from file.\u001b[39;00m\n\u001b[1;32m    125\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;124;03m4    4    9\u001b[39;00m\n\u001b[1;32m    183\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    184\u001b[0m excs_to_catch \u001b[38;5;241m=\u001b[39m (\u001b[38;5;167;01mAttributeError\u001b[39;00m, \u001b[38;5;167;01mImportError\u001b[39;00m, \u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m)\n\u001b[0;32m--> 185\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    186\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    187\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    188\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    189\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    190\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    191\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m handles:\n\u001b[1;32m    192\u001b[0m     \u001b[38;5;66;03m# 1) try standard library Pickle\u001b[39;00m\n\u001b[1;32m    193\u001b[0m     \u001b[38;5;66;03m# 2) try pickle_compat (older pandas version) to handle subclass changes\u001b[39;00m\n\u001b[1;32m    194\u001b[0m     \u001b[38;5;66;03m# 3) try pickle_compat with latin-1 encoding upon a UnicodeDecodeError\u001b[39;00m\n\u001b[1;32m    196\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    197\u001b[0m         \u001b[38;5;66;03m# TypeError for Cython complaints about object.__new__ vs Tick.__new__\u001b[39;00m\n\u001b[1;32m    198\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/conda/envs/pytorch/lib/python3.10/site-packages/pandas/io/common.py:882\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[1;32m    874\u001b[0m             handle,\n\u001b[1;32m    875\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    878\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    879\u001b[0m         )\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m--> 882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    883\u001b[0m     handles\u001b[38;5;241m.\u001b[39mappend(handle)\n\u001b[1;32m    885\u001b[0m \u001b[38;5;66;03m# Convert BytesIO or file objects passed with an encoding\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/jupyter/ai_font/data/pickle/letter2font.pickle'"
     ]
    }
   ],
   "source": [
    "from options import TrainOptions\n",
    "opt = TrainOptions()\n",
    "from x_dataset import CGGANDataset\n",
    "\n",
    "dataset = CGGANDataset(args=opt)\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    dataset, batch_size=opt.batch_size,\n",
    "    shuffle=True, sampler=None, drop_last=True, num_workers=int(opt.num_threads))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "be491b67-80c9-4825-9cea-620520bcd69e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "nclass = opt.n_alphabet+1\n",
    "channel_size = opt.input_nc\n",
    "hidden_size = opt.hidden_size\n",
    "output_size = opt.n_alphabet+2\n",
    "dropout_p = opt.dropout_p\n",
    "max_length = opt.max_length\n",
    "D_ch = opt.D_ch\n",
    "nWriter = opt.num_writer\n",
    "norm = opt.norm\n",
    "init_type = opt.init_type \n",
    "init_gain = opt.init_gain\n",
    "iam = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d6b1eb01-41cd-47c1-8345-da18260a3417",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "camD = CAM_normD(nclass,channel_size,hidden_size,output_size,dropout_p,max_length,D_ch,nWriter,iam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f667117-bf8c-4d74-9fd1-3becba25a94d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-env-pytorch-pytorch",
   "name": "workbench-notebooks.m120",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m120"
  },
  "kernelspec": {
   "display_name": "PyTorch 1-13 (Local)",
   "language": "python",
   "name": "conda-env-pytorch-pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
