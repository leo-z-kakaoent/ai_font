{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e81c37b1-9d19-4857-8cc3-0f0646f0b2b9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import models, transforms\n",
    "from PIL import Image\n",
    "import os\n",
    "from torchvision.models.segmentation import deeplabv3_mobilenet_v3_large as deeplab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84a661ec-e8d8-4602-bb46-9e8f9709d6be",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define a simple custom dataset\n",
    "class CustomSegmentationDataset(Dataset):\n",
    "    def __init__(self, image_paths, mask_paths, transform=None):\n",
    "        self.image_paths = image_paths\n",
    "        self.mask_paths = mask_paths\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image = Image.open(self.image_paths[idx]).convert(\"RGB\")\n",
    "        mask = Image.open(self.mask_paths[idx])\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            mask = self.transform(mask)\n",
    "        \n",
    "        return image, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b1e0f80-73b7-4345-9155-0810801d3ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data preparation\n",
    "image_dir = 'path_to_images'  # Replace with the path to your images\n",
    "mask_dir = 'path_to_masks'  # Replace with the path to your masks\n",
    "\n",
    "image_paths = [os.path.join(image_dir, f) for f in os.listdir(image_dir)]\n",
    "mask_paths = [os.path.join(mask_dir, f) for f in os.listdir(mask_dir)]\n",
    "\n",
    "train_images, val_images, train_masks, val_masks = train_test_split(image_paths, mask_paths, test_size=0.2, random_state=42)\n",
    "\n",
    "# Transforms\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((520, 520)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "train_dataset = CustomSegmentationDataset(train_images, train_masks, transform=transform)\n",
    "val_dataset = CustomSegmentationDataset(val_images, val_masks, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=4, shuffle=False)\n",
    "\n",
    "# Load the model\n",
    "model = models.segmentation.deeplabv3_mobilenet_v3_large(pretrained=True)\n",
    "model.classifier[4] = nn.Conv2d(256, 21, kernel_size=(1, 1), stride=(1, 1))  # Assuming 21 classes for segmentation\n",
    "model = model.cuda()  # Move the model to GPU if available\n",
    "\n",
    "# Loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for images, masks in train_loader:\n",
    "        images = images.cuda()\n",
    "        masks = masks.cuda()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = model(images)['out']\n",
    "        loss = criterion(outputs, masks.long())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader)}')\n",
    "    \n",
    "    # Validation loop\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for images, masks in val_loader:\n",
    "            images = images.cuda()\n",
    "            masks = masks.cuda()\n",
    "            \n",
    "            outputs = model(images)['out']\n",
    "            loss = criterion(outputs, masks.long())\n",
    "            \n",
    "            val_loss += loss.item()\n",
    "    \n",
    "    print(f'Validation Loss: {val_loss/len(val_loader)}')\n",
    "\n",
    "print('Training completed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a6ce6ef-b737-42d0-b09f-67b4532d2c61",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = deeplab(weights_backbone=\"DEFAULT\", num_classes=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b8f7da09-b4c5-40ed-8626-ab765612712f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "a = model(torch.ones(8,3,520,520))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "35148758-218c-49b2-9d91-613313ba55a2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.2251,  0.2251,  0.2251,  ...,  0.3271,  0.3271,  0.3271],\n",
       "         [ 0.2251,  0.2251,  0.2251,  ...,  0.3271,  0.3271,  0.3271],\n",
       "         [ 0.2251,  0.2251,  0.2251,  ...,  0.3271,  0.3271,  0.3271],\n",
       "         ...,\n",
       "         [-0.3126, -0.3126, -0.3126,  ...,  0.3252,  0.3252,  0.3252],\n",
       "         [-0.3126, -0.3126, -0.3126,  ...,  0.3252,  0.3252,  0.3252],\n",
       "         [-0.3126, -0.3126, -0.3126,  ...,  0.3252,  0.3252,  0.3252]],\n",
       "\n",
       "        [[ 2.9444,  2.9444,  2.9444,  ...,  0.3030,  0.3030,  0.3030],\n",
       "         [ 2.9444,  2.9444,  2.9444,  ...,  0.3030,  0.3030,  0.3030],\n",
       "         [ 2.9444,  2.9444,  2.9444,  ...,  0.3030,  0.3030,  0.3030],\n",
       "         ...,\n",
       "         [-0.0179, -0.0179, -0.0179,  ...,  0.3096,  0.3096,  0.3096],\n",
       "         [-0.0179, -0.0179, -0.0179,  ...,  0.3096,  0.3096,  0.3096],\n",
       "         [-0.0179, -0.0179, -0.0179,  ...,  0.3096,  0.3096,  0.3096]],\n",
       "\n",
       "        [[-0.9134, -0.9134, -0.9134,  ...,  0.1181,  0.1181,  0.1181],\n",
       "         [-0.9134, -0.9134, -0.9134,  ...,  0.1181,  0.1181,  0.1181],\n",
       "         [-0.9134, -0.9134, -0.9134,  ...,  0.1181,  0.1181,  0.1181],\n",
       "         ...,\n",
       "         [-0.4665, -0.4665, -0.4665,  ..., -0.3049, -0.3049, -0.3049],\n",
       "         [-0.4665, -0.4665, -0.4665,  ..., -0.3049, -0.3049, -0.3049],\n",
       "         [-0.4665, -0.4665, -0.4665,  ..., -0.3049, -0.3049, -0.3049]],\n",
       "\n",
       "        [[-0.3622, -0.3622, -0.3622,  ..., -1.6527, -1.6527, -1.6527],\n",
       "         [-0.3622, -0.3622, -0.3622,  ..., -1.6527, -1.6527, -1.6527],\n",
       "         [-0.3622, -0.3622, -0.3622,  ..., -1.6527, -1.6527, -1.6527],\n",
       "         ...,\n",
       "         [-0.6827, -0.6827, -0.6827,  ..., -0.3255, -0.3255, -0.3255],\n",
       "         [-0.6827, -0.6827, -0.6827,  ..., -0.3255, -0.3255, -0.3255],\n",
       "         [-0.6827, -0.6827, -0.6827,  ..., -0.3255, -0.3255, -0.3255]]],\n",
       "       grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a['out'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2ae8a122-7ef6-4d8a-b883-960f54dd1218",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 4, 520, 520])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a['out'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d317592-e02b-4245-93db-25739bc6589a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-env-pytorch-pytorch",
   "name": "workbench-notebooks.m122",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m122"
  },
  "kernelspec": {
   "display_name": "PyTorch 1-13 (Local)",
   "language": "python",
   "name": "conda-env-pytorch-pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
