{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9adeb032-09b5-406d-830a-124a71d75888",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.models import efficientnet_b7, EfficientNet_B7_Weights\n",
    "import pandas as pd\n",
    "from args import Args\n",
    "import copy\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import os\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from google.cloud import storage\n",
    "\n",
    "storage_client = storage.Client(\"leo_font\")\n",
    "bucket = storage_client.bucket(\"leo_font\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "29f7c101-d4e9-4b8d-ad87-41356a02af57",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "args = Args()\n",
    "\n",
    "# Define transforms\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b3d9bdd-a18e-473f-a76f-92a2972d73df",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, root_dir, labeler, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.args = args\n",
    "        self.labeler = labeler\n",
    "        self.files = [f\"{root_dir}/{f}\" for f in os.listdir(root_dir) if \".png\" in f]\n",
    "\n",
    "    def __len__(self):\n",
    "        # return int(len(self.files)/100)\n",
    "        return len(self.files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        path = self.files[idx]\n",
    "        letter = path.split(\"__\")[-1].replace(\".png\",\"\")\n",
    "        cho, jung, jong = self.labeler[letter]\n",
    "        cho = np.eye(19)[cho]\n",
    "        jung = np.eye(21)[jung]\n",
    "        jong = np.eye(28)[jong]\n",
    "        image = Image.open(path)\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, torch.from_numpy(cho), torch.from_numpy(jung), torch.from_numpy(jong)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a19d8d03-74fd-4d02-944f-2cbefb1c362b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CustomPerformancer:\n",
    "    def __init__(self):\n",
    "        self.total = 0\n",
    "        self.total_correct = 0\n",
    "        self.cho_correct = 0\n",
    "        self.jung_correct = 0\n",
    "        self.jong_correct = 0\n",
    "        self.histories = defaultdict(list)\n",
    "    \n",
    "    def reset(self):\n",
    "        self.total = 0\n",
    "        self.total_correct = 0\n",
    "        self.cho_correct = 0\n",
    "        self.jung_correct = 0\n",
    "        self.jong_correct = 0\n",
    "    \n",
    "    def take(self, outs, labels):\n",
    "        choout, jungout, jongout = outs\n",
    "        chol, jungl, jongl = labels\n",
    "        \n",
    "        _, chopred = choout.max(1)\n",
    "        _, choreal = chol.max(1)\n",
    "        chocorr = chopred.eq(choreal)\n",
    "        \n",
    "        _, jungpred = jungout.max(1)\n",
    "        _, jungreal = jungl.max(1)\n",
    "        jungcorr = jungpred.eq(jungreal)\n",
    "        \n",
    "        _, jongpred = jongout.max(1)\n",
    "        _, jongreal = jongl.max(1)\n",
    "        jongcorr = jongpred.eq(jongreal)\n",
    "        \n",
    "        allcorr = chocorr & jungcorr & jongcorr\n",
    "\n",
    "        self.total += len(allcorr)\n",
    "        self.total_correct += sum(allcorr).item()\n",
    "        self.cho_correct += sum(chocorr).item()\n",
    "        self.jung_correct += sum(jungcorr).item()\n",
    "        self.jong_correct += sum(jongcorr).item()\n",
    "        \n",
    "    def accuracies(self):\n",
    "        return {\n",
    "            \"total_accuracy\": self.total_correct/self.total,\n",
    "            \"cho_accuracy\": self.cho_correct/self.total,\n",
    "            \"jung_accuracy\": self.jung_correct/self.total,\n",
    "            \"jong_accuracy\": self.jong_correct/self.total,\n",
    "            \"count\": self.total,\n",
    "        }\n",
    "    \n",
    "    def save_history(self, name):\n",
    "        self.histories[name].append(self.accuracies())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e8709cde-e6e4-4189-b769-1c7e1938e592",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def save_model(state_dict, save_path):\n",
    "    blob = bucket.blob(save_path)\n",
    "    with blob.open(\"wb\", ignore_flush=True) as f:\n",
    "        torch.save(state_dict, f)\n",
    "        \n",
    "def save_history(hist, save_path):\n",
    "    blob = bucket.blob(save_path)\n",
    "    with blob.open(\"wb\", ignore_flush=True) as f:\n",
    "        pd.DataFrame().from_dict(hist).to_csv(f)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6d787b4c-ceac-4388-b3ab-068d1424b4b0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load data\n",
    "train_dataset = CustomDataset(root_dir=f'{args.datapath}/seen', labeler=args.labels, transform=transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=24, shuffle=True, num_workers=10)\n",
    "test_dataset = CustomDataset(root_dir=f'{args.datapath}/unseen', labeler=args.labels, transform=transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=24, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "73a9c4c4-6eda-4da7-8197-83954d7db026",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ModifiedEfficientNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ModifiedEfficientNet, self).__init__()\n",
    "        self.effnet = efficientnet_b7(weights=EfficientNet_B7_Weights.IMAGENET1K_V1)\n",
    "        in_features = 1000\n",
    "        self.cho_fc = nn.Linear(in_features, 19)\n",
    "        self.jung_fc = nn.Linear(in_features, 21)\n",
    "        self.jong_fc = nn.Linear(in_features, 28)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.effnet(x)\n",
    "        cho_out = self.cho_fc(x)\n",
    "        jung_out = self.jung_fc(x)\n",
    "        jong_out = self.jong_fc(x)\n",
    "        return cho_out, jung_out, jong_out\n",
    "    \n",
    "    def set_feature_extractor_trainable(self, trainable):\n",
    "        for param in self.effnet.parameters():\n",
    "            param.requires_grad = trainable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1cc87608-1257-4dac-9981-da8e17851abb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = ModifiedEfficientNet()\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ad579021-d3a2-461b-af81-d1f9dbf08007",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27453"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed962cf-bcff-486a-9269-a752db3a4ed7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 35040/2952000 [1:56:13<429:32:05,  1.89it/s, acc=0.9033, mode=train] "
     ]
    }
   ],
   "source": [
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "perf = CustomPerformancer()\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 100\n",
    "pbar = tqdm(total= num_epochs*(len(train_loader)+len(test_loader)))\n",
    "# pbar = tqdm(total= num_epochs*len(train_loader))\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    if epoch == 0:\n",
    "        save_model(model.state_dict(),f\"{args.savepath}/effnet_{epoch}.pth\")\n",
    "        save_history(perf.histories['train'], f\"{args.savepath}/train_history.csv\")\n",
    "        save_history(perf.histories['test'], f\"{args.savepath}/test_history.csv\")\n",
    "    \n",
    "    model.train()\n",
    "    if epoch == 0:\n",
    "        model.set_feature_extractor_trainable(False)\n",
    "    else:\n",
    "        model.set_feature_extractor_trainable(True)\n",
    "    perf.reset()\n",
    "    for inputs, cho, jung, jong in train_loader:\n",
    "        inputs, cho, jung, jong = inputs.to(device), cho.to(device), jung.to(device), jong.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        cho_out, jung_out, jong_out = model(inputs)\n",
    "        loss = criterion(cho_out, cho)\n",
    "        loss += criterion(jung_out, jung)\n",
    "        loss += criterion(jong_out, jong)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        perf.take([cho_out.cpu(), jung_out.cpu(), jong_out.cpu()],[cho.cpu(),jung.cpu(),jong.cpu()])\n",
    "        pbar.update(1)\n",
    "        pbar.set_postfix(mode='train', acc=f\"{perf.accuracies()['total_accuracy']:.4f}\")\n",
    "\n",
    "    perf.save_history('train')\n",
    "    perf.reset()\n",
    "    model.eval()\n",
    "    for inputs, cho, jung, jong in test_loader:\n",
    "        inputs, cho, jung, jong = inputs.to(device), cho.to(device), jung.to(device), jong.to(device)\n",
    "        cho_out, jung_out, jong_out = model(inputs)\n",
    "        perf.take([cho_out.cpu(), jung_out.cpu(), jong_out.cpu()],[cho.cpu(),jung.cpu(),jong.cpu()])\n",
    "        pbar.update(1)\n",
    "        pbar.set_postfix(mode='test', acc=f\"{perf.accuracies()['total_accuracy']:.4f}\")\n",
    "    perf.save_history('test')\n",
    "    \n",
    "    save_model(model.state_dict(),f\"{args.savepath}/effnet_{epoch}.pth\")\n",
    "    save_history(perf.histories['train'], f\"{args.savepath}/train_history.csv\")\n",
    "    save_history(perf.histories['test'], f\"{args.savepath}/test_history.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e5eb8d-7365-473b-aa55-c6b7eef88230",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-env-pytorch-pytorch",
   "name": "workbench-notebooks.m120",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m120"
  },
  "kernelspec": {
   "display_name": "PyTorch 1-13 (Local)",
   "language": "python",
   "name": "conda-env-pytorch-pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
